{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"markdown","source":"#### Setup","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-09-24T06:45:54.897576Z","iopub.execute_input":"2022-09-24T06:45:54.898005Z","iopub.status.idle":"2022-09-24T06:45:54.903928Z","shell.execute_reply.started":"2022-09-24T06:45:54.897970Z","shell.execute_reply":"2022-09-24T06:45:54.902747Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/einops')\nsys.path.append('../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master')\nsys.path.append('../input/coatmodeltrain')\n#from efficientnet_pytorch import EfficientNet\n!pip install ../input/einops-030/einops-0.3.0-py2.py3-none-any.whl\n# !pip install --upgrade efficientnet-pytorch\n#import efficientnet_pytorch\n\n#!python3 ../input/coatmodeltrain/CoatModel.py\n#from coatmodeltrain import *\n#!python3 ../input/coatmodeltrain/EfficientModelTrain.py","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-09-25T11:22:01.022537Z","iopub.execute_input":"2022-09-25T11:22:01.023010Z","iopub.status.idle":"2022-09-25T11:22:31.819495Z","shell.execute_reply.started":"2022-09-25T11:22:01.022918Z","shell.execute_reply":"2022-09-25T11:22:31.818120Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/einops-030/einops-0.3.0-py2.py3-none-any.whl\nInstalling collected packages: einops\nSuccessfully installed einops-0.3.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import albumentations as A\n","metadata":{"execution":{"iopub.status.busy":"2022-09-25T11:22:31.823194Z","iopub.execute_input":"2022-09-25T11:22:31.823895Z","iopub.status.idle":"2022-09-25T11:22:33.349399Z","shell.execute_reply.started":"2022-09-25T11:22:31.823850Z","shell.execute_reply":"2022-09-25T11:22:33.348125Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"sys.path.append('../input/coatmodeltrain/')\n","metadata":{"execution":{"iopub.status.busy":"2022-09-25T11:22:33.350843Z","iopub.execute_input":"2022-09-25T11:22:33.351274Z","iopub.status.idle":"2022-09-25T11:22:33.357030Z","shell.execute_reply.started":"2022-09-25T11:22:33.351231Z","shell.execute_reply":"2022-09-25T11:22:33.355917Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from CoatModel import *","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs, image_size):\n    best_acc = 0.0\n    best_loss = 10.0\n    for epoch in range(num_epochs):\n        model.cuda()       \n        for phase in ['train', 'val']:\n            if phase == 'train': model.train()\n            else: model.eval()\n            epoch_loss = 0.0\n            epoch_acc = 0\n            \n            \n            dataloader = dataloaders_dict[phase]\n            for item in tqdm(dataloader, leave=False):\n                images = item[0].cuda().float()\n                classes = item[1].cuda().long()\n                optimizer.zero_grad()                \n                with torch.set_grad_enabled(phase == 'train'):\n                    output = model(images)\n                    loss = criterion(output, classes)\n                    _, preds = torch.max(output, 1)\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                    epoch_loss += loss.item() * len(output)\n                    epoch_acc += torch.sum(preds == classes.data)   \n                del images\n                del classes\n                gc.collect()\n            data_size = len(dataloader.dataset)\n            epoch_loss = epoch_loss / data_size\n            epoch_acc = epoch_acc.double() / data_size\n            print(f'Epoch {epoch + 1}/{num_epochs} | {phase:^5} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}')    \n#         if epoch_acc > best_acc:\n#             traced = torch.jit.trace(model.cpu(), torch.rand(1, 3, image_size, image_size))\n#             traced.save('model.pth')\n#             best_acc = epoch_acc\n#             del traced\n#             gc.collect()\n        if epoch_loss < best_loss:\n            traced = torch.jit.trace(model.cpu(), torch.rand(1, 3, image_size, image_size))\n            traced.save('model_Best_loss.pth')\n            best_loss = epoch_loss\n            del traced\n            gc.collect()\n \n","metadata":{"execution":{"iopub.status.busy":"2022-09-25T10:13:17.660358Z","iopub.execute_input":"2022-09-25T10:13:17.660975Z","iopub.status.idle":"2022-09-25T10:13:17.672204Z","shell.execute_reply.started":"2022-09-25T10:13:17.660935Z","shell.execute_reply":"2022-09-25T10:13:17.671000Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"debug = False\ngenerate_new = False\ntrain_df = pd.read_csv(\"../input/mayo-clinic-strip-ai/train.csv\").head(1000)\ntest_df = pd.read_csv(\"../input/mayo-clinic-strip-ai/test.csv\")\ndirs = [\"../input/mayo-clinic-strip-ai/train/\", \"../input/mayo-clinic-strip-ai/test/\"]","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":3.063995,"end_time":"2022-07-08T14:24:41.045696","exception":false,"start_time":"2022-07-08T14:24:37.981701","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-25T11:24:07.148467Z","iopub.execute_input":"2022-09-25T11:24:07.148908Z","iopub.status.idle":"2022-09-25T11:24:07.174286Z","shell.execute_reply.started":"2022-09-25T11:24:07.148874Z","shell.execute_reply":"2022-09-25T11:24:07.173265Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\nclass ImgDataset(Dataset):\n    def __init__(self, df, stage):\n        self.df = df \n        self.train = 'label' in df.columns    \n        \n        if stage == 'train':\n            self.transforms = A.Compose([\n                A.augmentations.Rotate(limit=90, p=0.5),\n                A.augmentations.HorizontalFlip(p=0.5),\n                A.augmentations.VerticalFlip(p=0.5),\n                A.augmentations.transforms.ColorJitter(p=0.5),\n            \n                A.OneOf([\n                    A.HueSaturationValue(10, 15, 10),\n                    A.RandomBrightnessContrast(),            \n                ], p=0.5),                \n                A.Normalize(),\n            ])\n        else:\n            self.transforms = A.Compose([\n                A.Normalize(),\n            ])\n        \n        \n        \n    def __len__(self): return len(self.df)    \n    def __getitem__(self, index):\n        if(generate_new): paths = [\"./test/\", \"./train/\"]\n        else: paths = [\"../input/jpg-images-strip-ai/test/\", \"../input/mayoclinicai-224456600-resized-training-images/resized_training_dataset/img_1024_folder/\"]\n        \n        if paths == \"../input/jpg-images-strip-ai/test/\":\n            image = cv2.imread(paths[self.train] + self.df.iloc[index].image_id + \".jpg\")\n        else:\n            image = cv2.imread(paths[self.train] + self.df.iloc[index].image_id + \".jpg\")\n            \n        \n        #image = cv2.resize(image, (512, 512))#.transpose(2, 0, 1)\n        #image = cv2.resize(tifffile.imread(paths[self.train] + self.df.iloc[index].image_id + \".jpg\"), (512, 512))\n        \n        img = self.transforms(image=cv2.resize(image, (512, 512)))[\"image\"]\n        \n        if len(img.shape) == 5:\n            img_squeeze = img.squeeze().transpose(1, 2, 0)\n        image = img_squeeze.transpose(2, 0, 1)\n        label = None\n        if(self.train): label = {\"CE\" : 0, \"LAA\": 1}[self.df.iloc[index].label]\n        del img\n        del img_squeeze\n        gc.collect()  \n        return image, label","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-25T11:24:23.087958Z","iopub.execute_input":"2022-09-25T11:24:23.088910Z","iopub.status.idle":"2022-09-25T11:24:23.102739Z","shell.execute_reply.started":"2022-09-25T11:24:23.088860Z","shell.execute_reply":"2022-09-25T11:24:23.101478Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"#### Architecture Definition & Running the training","metadata":{}},{"cell_type":"code","source":"num_blocks = [2, 6, 12, 28, 6] #[2, 2, 6, 8, 2]\nchannels = [64, 64, 128, 256, 512]\n#model = torch.jit.load('../input/coatmodeltrain/model.pth')\nmodel = CoAtNet((512, 512), 3, num_blocks, channels, num_classes=2)\ntrain, val = train_test_split(train_df, test_size=0.2, random_state=42, stratify = train_df.label)\nbatch_size = 1\ntrain_loader = DataLoader(ImgDataset(train, 'train'), batch_size=4, shuffle=False, num_workers=2)\nval_loader = DataLoader(ImgDataset(val, 'val'), batch_size=batch_size, shuffle=False, num_workers=1)\ndataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=8e-5)\ntrain_model(model, dataloaders_dict, criterion, optimizer, 30, 512)\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\ntrain_model(model, dataloaders_dict, criterion, optimizer, 30, 512)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-25T10:13:36.010132Z","iopub.execute_input":"2022-09-25T10:13:36.010874Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 1/30 | train | Loss: 0.9023 | Acc: 0.6434\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 1/30 |  val  | Loss: 0.5886 | Acc: 0.7285\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 2/30 | train | Loss: 0.6633 | Acc: 0.6866\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 2/30 |  val  | Loss: 0.5612 | Acc: 0.7351\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 3/30 | train | Loss: 0.6499 | Acc: 0.6949\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 3/30 |  val  | Loss: 0.5699 | Acc: 0.7285\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 4/30 | train | Loss: 0.6395 | Acc: 0.6965\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 4/30 |  val  | Loss: 0.5596 | Acc: 0.7285\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 5/30 | train | Loss: 0.6267 | Acc: 0.7081\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 5/30 |  val  | Loss: 0.5635 | Acc: 0.7285\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 6/30 | train | Loss: 0.6258 | Acc: 0.7164\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 6/30 |  val  | Loss: 0.5556 | Acc: 0.7219\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 7/30 | train | Loss: 0.6215 | Acc: 0.7032\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 7/30 |  val  | Loss: 0.5831 | Acc: 0.7219\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 8/30 | train | Loss: 0.6172 | Acc: 0.7181\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 8/30 |  val  | Loss: 0.5871 | Acc: 0.7285\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 9/30 | train | Loss: 0.6091 | Acc: 0.7148\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 9/30 |  val  | Loss: 0.5488 | Acc: 0.7417\n","output_type":"stream"}]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2022-09-25T09:29:10.093682Z","iopub.execute_input":"2022-09-25T09:29:10.094021Z","iopub.status.idle":"2022-09-25T09:29:11.065629Z","shell.execute_reply.started":"2022-09-25T09:29:10.093941Z","shell.execute_reply":"2022-09-25T09:29:11.064282Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"__notebook_source__.ipynb\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### EfficientNet B4 - Training","metadata":{}},{"cell_type":"code","source":"#from EfficientModelTrain import *\nimport efficientnet_pytorch\nfrom efficientnet_pytorch import EfficientNet","metadata":{"execution":{"iopub.status.busy":"2022-09-25T11:22:33.359159Z","iopub.execute_input":"2022-09-25T11:22:33.360164Z","iopub.status.idle":"2022-09-25T11:22:35.036717Z","shell.execute_reply.started":"2022-09-25T11:22:33.360121Z","shell.execute_reply":"2022-09-25T11:22:35.035641Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport copy\nimport time\nimport torch\nimport random\nimport string\nimport joblib\nimport tifffile\nimport numpy as np \nimport pandas as pd \nfrom torch import nn\nimport seaborn as sns\n#import efficientnet_pytorch\nfrom torchvision import models\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom torch.optim import lr_scheduler\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport warnings; warnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-09-25T11:23:38.535904Z","iopub.execute_input":"2022-09-25T11:23:38.536597Z","iopub.status.idle":"2022-09-25T11:23:38.933225Z","shell.execute_reply.started":"2022-09-25T11:23:38.536561Z","shell.execute_reply":"2022-09-25T11:23:38.932197Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**Setups**","metadata":{}},{"cell_type":"code","source":"!mkdir /root/.cache/torch\n!mkdir /root/.cache/torch/hub\n!mkdir /root/.cache/torch/hub/checkpoints\n!cp -r ../input/torchhub-efficientnet-b7/nvidia_efficientnet-b7_210412.pth /root/.cache/torch/hub/checkpoints/","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-09-25T11:22:35.637378Z","iopub.execute_input":"2022-09-25T11:22:35.638157Z","iopub.status.idle":"2022-09-25T11:22:39.690880Z","shell.execute_reply.started":"2022-09-25T11:22:35.638042Z","shell.execute_reply":"2022-09-25T11:22:39.689660Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"cp: cannot stat '../input/torchhub-efficientnet-b7/nvidia_efficientnet-b7_210412.pth': No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"    \ndef train_model(model, dataloaders_dict, criterion, optimizer, num_epochs, img_size):\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        model.cuda()\n        \n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n                \n            epoch_loss = 0.0\n            epoch_acc = 0\n            \n            dataloader = dataloaders_dict[phase]\n            for item in tqdm(dataloader, leave=False):\n                images = item[0].cuda().float()\n                classes = item[1].cuda().long()\n\n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase == 'train'):\n                    output = model(images)\n                    loss = criterion(output, classes)\n                    _, preds = torch.max(output, 1)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                    epoch_loss += loss.item() * len(output)\n                    epoch_acc += torch.sum(preds == classes.data)\n                    \n\n            data_size = len(dataloader.dataset)\n            epoch_loss = epoch_loss / data_size\n            epoch_acc = epoch_acc.double() / data_size\n\n            print(f'Epoch {epoch + 1}/{num_epochs} | {phase:^5} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}')\n        \n        if epoch_acc > best_acc:\n            traced = torch.jit.trace(model.cpu(), torch.rand(1, 3, img_size, img_size))\n            traced.save('efficientnet_model.pth')\n            best_acc = epoch_acc","metadata":{"execution":{"iopub.status.busy":"2022-09-25T11:23:15.351669Z","iopub.execute_input":"2022-09-25T11:23:15.352106Z","iopub.status.idle":"2022-09-25T11:23:15.365324Z","shell.execute_reply.started":"2022-09-25T11:23:15.352051Z","shell.execute_reply":"2022-09-25T11:23:15.364047Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"#### Running the training","metadata":{}},{"cell_type":"code","source":"model = efficientnet_pytorch.EfficientNet.from_name(\"efficientnet-b7\")\ncheckpoint = torch.load('../input/efficientnet-pytorch/efficientnet-b7-dcc49843.pth')\nmodel.load_state_dict(checkpoint)\n\ntrain, val = train_test_split(train_df, test_size=0.2, random_state=42, stratify = train_df.label)\nbatch_size = 1\ntrain_loader = DataLoader(ImgDataset(train, 'train'), batch_size=4, shuffle=False, num_workers=1)\nval_loader = DataLoader(ImgDataset(val, 'val'), batch_size=batch_size, shuffle=False, num_workers=1)\ndataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\ntrain_model(model, dataloaders_dict, criterion, optimizer, 2,512)\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\ntrain_model(model, dataloaders_dict, criterion, optimizer, 10, 512)","metadata":{"execution":{"iopub.status.busy":"2022-09-25T11:32:35.266235Z","iopub.execute_input":"2022-09-25T11:32:35.266666Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 1/2 | train | Loss: 1.5641 | Acc: 0.6368\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 1/2 |  val  | Loss: 0.7114 | Acc: 0.6689\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 2/2 | train | Loss: 0.6268 | Acc: 0.7032\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 2/2 |  val  | Loss: 0.6281 | Acc: 0.7285\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 1/10 | train | Loss: 0.5486 | Acc: 0.7380\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 1/10 |  val  | Loss: 0.6000 | Acc: 0.7152\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 2/10 | train | Loss: 0.5205 | Acc: 0.7546\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 2/10 |  val  | Loss: 0.5932 | Acc: 0.7285\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 3/10 | train | Loss: 0.5124 | Acc: 0.7546\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 3/10 |  val  | Loss: 0.6133 | Acc: 0.7020\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 4/10 | train | Loss: 0.4883 | Acc: 0.7944\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 4/10 |  val  | Loss: 0.5969 | Acc: 0.7219\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41eee45266104932897840fb8d7cb33e"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Efficientnet Inference","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport copy\nimport time\nimport random\nimport torch\nimport string\nimport joblib\nimport tifffile\nimport numpy as np \nimport pandas as pd \nfrom torch import nn\nimport seaborn as sns\nimport efficientnet_pytorch\nfrom tqdm.notebook import tqdm\nfrom torchvision import models\nimport matplotlib.pyplot as plt\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport warnings; warnings.filterwarnings(\"ignore\")\n\ngc.enable()\ndebug = False\ngenerate_new = True\ntest_df = pd.read_csv(\"../input/mayo-clinic-strip-ai/test.csv\")\ndirs = [\"../input/mayo-clinic-strip-ai/train/\", \"../input/mayo-clinic-strip-ai/test/\"]\ntest_df\n\ntry:\n    os.mkdir(\"../test/\")\nexcept:\n    pass\nfor i in tqdm(range(test_df.shape[0])):\n    img_id = test_df.iloc[i].image_id\n    try:\n        sz = os.path.getsize(dirs[1] + img_id + \".tif\")\n    except:\n        sz = 1000000000\n    if(sz > 8e8):\n        img = np.zeros((768,768,3), np.uint8)\n    else:\n        try:\n            img = cv2.resize(tifffile.imread(dirs[1] + img_id + \".tif\"), (768, 768))\n        except:\n            img = np.zeros((768,768,3), np.uint8)\n    cv2.imwrite(f\"../test/{img_id}.jpg\", img)\n    del img\n    gc.collect()\n    \n    \nclass ImgDataset(Dataset):\n    def __init__(self, df):\n        self.df = df \n        self.train = 'label' in df.columns\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        if(generate_new):\n            paths = [\"../test/\", \"../train/\"]\n        else:\n            paths = [\"../input/jpg-images-strip-ai/test/\", \"../input/jpg-images-strip-ai/train/\"]\n        try:\n            image = cv2.imread(paths[self.train] + self.df.iloc[index].image_id + \".jpg\")\n        except:\n            image = np.zeros((768,768,3), np.uint8)\n        label = 0\n        try:\n            if len(image.shape) == 5:\n                image = image.squeeze().transpose(1, 2, 0)\n            image = cv2.resize(image, (768, 768)).transpose(2, 0, 1)\n        except:\n            image = np.zeros((3, 768, 768))\n        if(self.train):\n            label = {\"CE\" : 0, \"LAA\": 1}[self.df.iloc[index].label]\n        patient_id = self.df.iloc[index].patient_id\n        return image, label, patient_id\ndef predict(model, dataloader):\n    model.cuda()\n    model.eval()\n    dataloader = dataloader\n    outputs = []\n    s = nn.Softmax(dim=1)\n    ids = []\n    for item in tqdm(dataloader, leave=False):\n        patient_id = item[2][0]\n        try:\n            images = item[0].cuda().float()\n            ids.append(patient_id)\n            output = model(images)\n            outputs.append(s(output.cpu()[:,:2])[0].detach().numpy())\n        except:\n            ids.append(patient_id)\n            outputs.append(s(torch.tensor([[1, 1]]).float())[0].detach().numpy())\n    return np.array(outputs), ids\n\n\nmodel = torch.jit.load('efficientnet_model.pth')\nbatch_size = 1\ntest_loader = DataLoader(\n    ImgDataset(test_df), \n    batch_size=batch_size, \n    shuffle=False, \n    num_workers=1\n)\nanss, ids = predict(model, test_loader)\n\nprob = pd.DataFrame({\"CE\" : anss[:,0], \"LAA\" : anss[:,1], \"id\" : ids}).groupby(\"id\").mean()\nsubmission = pd.read_csv(\"../input/mayo-clinic-strip-ai/sample_submission.csv\")\nsubmission.CE = prob.CE.to_list()\nsubmission.LAA = prob.LAA.to_list()\nsubmission.to_csv(\"submission_efficientnet.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-09-24T05:34:07.005737Z","iopub.execute_input":"2022-09-24T05:34:07.006126Z","iopub.status.idle":"2022-09-24T05:34:54.644153Z","shell.execute_reply.started":"2022-09-24T05:34:07.006093Z","shell.execute_reply":"2022-09-24T05:34:54.642996Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"029dfbec5b6c4c22be298017adbab79f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"markdown","source":"# Ensemble\n\nNow that we got both our models ready, we can simply combine the predictions of both and use them as an ensemble!\nWe do this by running the predictions and averaging them. This yields a more powerful model.","metadata":{}},{"cell_type":"code","source":"submission_coatnet = pd.read_csv(\"submission_coatnet.csv\")\nsubmission_efficientnet = pd.read_csv(\"submission_efficientnet.csv\")\nsub_df = pd.read_csv('../input/mayo-clinic-strip-ai/sample_submission.csv')\n\nsub_df['CE'] = (submission_efficientnet['CE'].values + submission_coatnet['CE'].values) / 2.0\nsub_df['LAA'] = (submission_efficientnet['LAA'].values + submission_coatnet['LAA'].values) / 2.0\n\n\nsub_df.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-09-24T05:34:59.560404Z","iopub.execute_input":"2022-09-24T05:34:59.560896Z","iopub.status.idle":"2022-09-24T05:34:59.584214Z","shell.execute_reply.started":"2022-09-24T05:34:59.560854Z","shell.execute_reply":"2022-09-24T05:34:59.583018Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\n\n#%cd ../../..\n!pwd\n#!cp -r ./00003570.model.pth .\nimport os\n#os.chdir(r'/kaggle/working')\nos.chdir(r'/kaggle/working/')\nFileLink(r'model.pth')","metadata":{"execution":{"iopub.status.busy":"2022-09-24T05:37:54.922106Z","iopub.execute_input":"2022-09-24T05:37:54.922591Z","iopub.status.idle":"2022-09-24T05:37:56.505047Z","shell.execute_reply.started":"2022-09-24T05:37:54.922554Z","shell.execute_reply":"2022-09-24T05:37:56.503784Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/model.pth","text/html":"<a href='model.pth' target='_blank'>model.pth</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}